{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358a65be-40a6-4c52-a0e6-e94f630fed23",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "        <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391ca98-2d64-4a3a-822c-370587a4174a",
   "metadata": {},
   "source": [
    "### Analyse search terms on the e-commerce web server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12889be-b54e-4830-8212-bcc10855f674",
   "metadata": {},
   "source": [
    "##### In this assignment you will download the search term data set for the e-commerce web server and run analytic queries on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd0075c-684f-4d99-9e20-4b836dd81573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/thangquang/.local/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/thangquang/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in /home/thangquang/.local/lib/python3.10/site-packages (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install spark\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297e5f47-53b5-4a64-99be-983b8af077fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764d2a7b-c242-47e4-972e-a15fe81b4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/06 21:17:11 WARN Utils: Your hostname, thangquang-Aspire-A715-41G resolves to a loopback address: 127.0.1.1; using 10.0.240.160 instead (on interface wlp4s0)\n",
      "24/11/06 21:17:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/thangquang/Documents/CODE/learn-spark/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/06 21:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Start session\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import  SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"My DE Capstone Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4517d15-4705-437b-a723-e4c5d7970783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-06 21:17:15--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 233457 (228K) [text/csv]\n",
      "Saving to: ‘searchterms.csv.1’\n",
      "\n",
      "searchterms.csv.1   100%[===================>] 227,99K   231KB/s    in 1,0s    \n",
      "\n",
      "2024-11-06 21:17:17 (231 KB/s) - ‘searchterms.csv.1’ saved [233457/233457]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download The search term dataset from the below url\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b69b658-4b8d-4de2-8550-fe49235599b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv into a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb27866-4ae2-451b-9d86-6da117ba727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"searchterms.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3001137c-e6b6-4a9e-8c82-198ff672ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of rows and columns\n",
    "# Take a screenshot of the code and name it as shape.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a30710a-f2b2-4e37-aa8d-3018e230bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 10000\n",
      "Number of columns: 4\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.count()\n",
    "num_columns = len(df.columns)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f332302-65cf-47bc-bf6f-f4a8a20fd2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 5 rows\n",
    "# Take a screenshot of the code and name it as top5rows.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3ccd8d-f577-4ccc-89c4-1304ee42c98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+--------------+\n",
      "|day|month|year|    searchterm|\n",
      "+---+-----+----+--------------+\n",
      "| 12|   11|2021| mobile 6 inch|\n",
      "| 12|   11|2021| mobile latest|\n",
      "| 12|   11|2021|   tablet wifi|\n",
      "| 12|   11|2021|laptop 14 inch|\n",
      "| 12|   11|2021|     mobile 5g|\n",
      "+---+-----+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adae0a63-8698-4421-8cd7-3126222a22c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the datatype of the column searchterm?\n",
    "# Take a screenshot of the code and name it as datatype.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85717fda-84d2-410a-a0eb-bae241d02c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- searchterm: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9cfe82-2e94-4a66-8bde-bc000bfa5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times was the term `gaming laptop` searched?\n",
    "# Take a screenshot of the code and name it as gaminglaptop.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8772f0-99c4-4a47-b575-ed8124cca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(condition=\"searchterm == 'gaming laptop'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ce5eab9-db67-4d7e-9e95-ff0f9943e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 5 most frequently used search terms?\n",
    "# Take a screenshot of the code and name it as top5terms.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb8679c5-7c78-4fdf-9e75-7e46eba10776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   searchterm|count|\n",
      "+-------------+-----+\n",
      "|mobile 6 inch| 2312|\n",
      "|    mobile 5g| 2301|\n",
      "|mobile latest| 1327|\n",
      "|       laptop|  935|\n",
      "|  tablet wifi|  896|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupBy(\"searchterm\").count().orderBy(desc(\"count\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88b86201-02da-496d-ad4d-36a89d750c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-06 21:17:25--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1490 (1,5K) [application/x-tar]\n",
      "Saving to: ‘model.tar.gz.1’\n",
      "\n",
      "model.tar.gz.1      100%[===================>]   1,46K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-11-06 21:17:26 (844 MB/s) - ‘model.tar.gz.1’ saved [1490/1490]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The pretrained sales forecasting model is available at  the below url\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d279dfa-aca8-48c5-8af4-2fc6e113b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sales forecast model.\n",
    "# Take a screenshot of the code and name it as loadmodel.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe17c5d-6b10-45b4-930a-2ac1c1ab2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "model = LinearRegressionModel.load(\"sales_prediction.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59161500-aaea-486d-9466-3813cff9bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the sales forecast model, predict the sales for the year of 2023.\n",
    "# Take a screenshot of the code and name it as forecast.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|        prediction|\n",
      "+----+------------------+\n",
      "|2023|175.16564294006457|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def predict(year):\n",
    "    # Assuming the features are 'day', 'month', and 'year'\n",
    "    assembler = VectorAssembler(inputCols=['year'], outputCol='features')\n",
    "    columns = [\"year\"]\n",
    "    data = [[year]]\n",
    "    df = spark.createDataFrame(data, columns)\n",
    "    df = assembler.transform(df)\n",
    "    predictions = model.transform(df)\n",
    "    predictions.select('year', 'prediction').show()\n",
    "\n",
    "predict(2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
